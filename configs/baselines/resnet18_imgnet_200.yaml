__BASE__: null

model:
  name: resnet18
  args:
    pretrained: false
    num_classes: 200
  input_size: [1, 3, 224, 224]

wrapper:
  name: ParametrizedQuantWrapper
  args:
    quant_conf:
      mode: linear
      bit_width: 4
      align_zero: false
    do_fold_bn: false
    fp_layers: null

epochs: 120
work_flow:
  - ["train", 1]
  - ["val", 1]

train:
  data_loader:
    args:
      batch_size: 64
      shuffle: false
      pin_memory: true
      num_workers: 2
  optim_groups:
    - name: &n_w weight_params
      matches:
        - .*
      optim_type: SGD
      args:
        lr: 0.05
        momentum: 0.9
        weight_decay: !!float 1e-4
        nesterov: true
  loss:
    name: CEKL
    args: {}
  metrics:
    - name: TopK
      args:
        logits_names:
          - fp
        topk: [1, 5]
  lr_policies:
    - name: StepMultiOptim
      args:
        gamma: 0.1
        step: [60, 95]
        warmup: linear
        warmup_iters: 750  # ~4 epochs on b64x8 setting
        warmup_ratio: 0.5  # starts from 0.2
        scale_by_world_size: true
        by_epoch: true
        apply_to:
          - *n_w
  qat_policies:
    - name: SetupQuantOnce
      args:
        quant_mode: fp
    - name: ConstantVariable
      args:
        name: ce_loss_weight
        value: 1.0
    - name: Optimizer
      args:
        grad_clip: null
  ckpt_interval: 1

eval:
  data_loader:
    args:
      batch_size: 32
      shuffle: false
      pin_memory: true
      num_workers: 1
  metrics:
    - name: DistEvalTopK
      args:
        logits_names:
          - fp
        topk: [1, 5]
  quant_mode:
    - fp

runtime_hooks: null

log:
  interval: 50
  hooks:
    - type: TextLoggerHook
    - type: EnhancedTBLoggerHook

dataset:
  name: ImageNetST
  args:
    img_dir: /mnt/lustre/share/images/
    meta_dir: /mnt/lustre/lirundong/Data/Meta/imagenet_dev/
    color: true

work_dir: /mnt/lustre/lirundong/Workspace/baselines/res18-imgnet-200/
pre_trained: null
resume: /mnt/lustre/lirundong/Workspace/baselines/res18-imgnet-200/epoch_90.pth
