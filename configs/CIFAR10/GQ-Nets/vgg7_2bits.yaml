BATCH_SIZE_PER_GPU: &bs 256
TOTAL_EPOCHS: &e 300

## Dataset
data:
  dataset:
    type: CIFAR10
    args:
      root: /mnt/lustre/lirundong/Data/Datasets/CIFAR
  train_loader_conf:
    batch_size: *bs
    shuffle: false
    pin_memory: true
    num_workers: 2
  train_sampler_conf:
    batch_size: *bs
    total_epoch: *e
  val_loader_conf:
    batch_size: *bs
    shuffle: false
    pin_memory: true
    num_workers: 1

## Models
arch:
  type: cifar10_vgg7_idq
  args:
    kw: 2
    ka: 2
    align_zero: false
    use_multi_domain: true
  gpu_per_model: 1
teacher_arch: null

## Loss
loss:
  type: InvDistilLoss
  args:
    soft_weight: null
    temperature: 1.0
    detach_ref: true
  topk: [1, 5]

## Optimization
param_group:
  conf:
    - type: Adam
      args: &weight_group
        lr: !!float 1e-3
        weight_decay: !!float 1e-4
    - type: Adam
      args: &quant_param_group
        lr: !!float 1e-3
        weight_decay: 0.0
  groups:
    - <<: *weight_group
    - <<: *quant_param_group
  args:
    ft_layers: null
opt:
  args:
    alter_step: 1
schedule:
  quant_start_iter: 0
  opt_cfgs: []
  variable_cfgs:
    - ["soft_w", 0.5]
    - ["hard_w", 0.5]
    - ["ref_w", 0.5]

## Evaluation
eval:
  freq: 1000
  vis: false
  quant: true
  calibrate: false
  use_ema_stat: true

## Resume and snapshot
ckpt:
  freq: 1000000
  dir: /mnt/lustre/lirundong/Data/quant-prob/cifar10/vgg7/2bits/checkpoints/
resume:
  path: null
  load_opt: true
  load_scheduler: true

## Logging and diagnose
log:
  freq: 500
  tb_dir: /mnt/lustre/lirundong/Data/quant-prob/cifar10/vgg7/2bits/tb_logs/
  file: /mnt/lustre/lirundong/Data/quant-prob/cifar10/vgg7/2bits/train
diagnose:
  enabled: false
  diagnoser:
    type: null
    args: {}
  tasks: []

## Misc
comment: "2bits_vgg7"
progress_bar: false
quant:
  enable_fp: true
  calib:
    steps: 5
    gamma: !!float 0.999
    required_on_training: true
    update_bn: false
distil:
  mode: inv_distil # {null, inv_distil, distil}
  zero_momentum: false
